\section{Brainf*ck}\label{section:brainfck}                                                       
Brainf*ck is often introduced as a programming language, which it is. Just like any other programming language, it allows the programmer to write programs consisting of commands that are executed in order. There is a total of 8 commands available to the programmer, written as single characters: ``\texttt{+-<>[].,}''. Each of these commands corresponds to an operation on an array of memory or a pointer, pointing to some location within this memory. At the start of the program, every cell in memory is initialized to 0 and the pointer is pointing to the very first element (index 0). The commands then modify the contents of memory and the pointer as follows:
\subsection{BF as a Language}
\begin{itemize}
\item \texttt{+} : add 1 to the current cell;
\item \texttt{-} : subtract 1 from the current cell;
\item \texttt{<} : move the pointer 1 cell to its left;
\item \texttt{>} : move the pointer 1 cell to its right;
\item \texttt{[} : if the current cell is nonzero, continue. Otherwise, skip to the matching closing \texttt{]};
\item \texttt{]} : if the current cell is zero, continue. Otherwise, loop back to its matching opening \texttt{[};
  \item \texttt{.} : send the value in the current cell to the output;
  \item \texttt{,} : read a value from the input and store it into the current cell.
\end{itemize}
Although this might seem like a very limited set of instructions, it has been proven to be sufficient for performing any possible computation or program, also known as Turing-completeness \cite{esolang}. The catch is that this requires an unbounded (or infinite) amount of memory, which is obviously impossible. However, the same caveat holds for traditional (von Neumann architecture) systems, so we should be safe to assume that BF is Turing complete for all practical purposes.

\subsection{Architectures}
\subsubsection{Von Neumann}
Modern computers are built according to the von Neumann architecture \cite{vonneumann-wiki}, which specifies a CPU (containing registers and an ALU), a single unit of memory and input/output devices (Figure \ref{fig:vonneumann}). The registers of the CPU can be loaded with data from the memory unit and operated on by the ALU (Arithmetic and Logic Unit). Typical about this kind of architecture is the fact that not only data, but also the instructions (the program) are stored in memory. The program is therefore just as much part of the data as the data itself and can even be modified by itself.
\begin{figure}[H]
  \centering
  \includegraphics[width=0.9\textwidth]{img/vonneumann}
  \caption{Schematic overview of the Von Neumann architecture.}
  \label{fig:vonneumann}
\end{figure}

\subsubsection{Harvard}
Unlike within the Von Neumann architecture, the Harvard architecture specifies two kinds of memory: program memory and data memory (Figure \ref{fig:harvard}). The program memory contains only the instructions to be carried out and cannot be modified at runtime. Other than that, the architecture is similar to Von Neumann, in that it consists of a CPU (again containing registers and an ALU), memory (program and data) and input/output devices.
\begin{figure}[H]
  \centering
  \includegraphics[width=0.9\textwidth]{img/harvard}
  \caption{Schematic overview of the Harvard architecture.}
  \label{fig:harvard}
\end{figure}


\subsubsection{BF Architecture}
The architecture assumed by the BF language is similar to the Harvard architecture, in that the memory does not contain the program itself. This implies that the program is stored somewhere else and cannot be addressed by the pointer. The ALU is very limited and can only perform increment, decrement and comparison to zero.


\subsubsection{BF as an Instruction Set}
Instead of viewing BF as a language that needs to be compiled or interpreted on a traditional machine, it can also be seen as an instruction set to a processor, built according to the BF architecture described above. An instruction set of size 8 is truly tiny compared to more traditional instruction sets such as those implemented by modern processors or even microcontrollers and older 8-bit systems. Broadly speaking, Complex Instruction Set Computers (CISC) are designed to do as much work as possible in the least number of clock cycles, whereas Reduced Instruction Set Computers focus on having small a instruction set with basic operations. For comparison, the x86 instruction set is massive with over 1500 instructions implemented in hardware, whereas RISC processors only need to implement 50 to 100 instuctions. Even compared to RISC, the BF instruction set (BFISC from hereon) is tiny even compared to the smallest instruction sets in use today. This isn't necessarily a good thing; a smaller number of instructions simply means you need more of them to perform meaningful computations, which is reflected by the fact that complex BF programs are typically very large in size.

\subsection{Brainfix}
In 2013, one of the authors wrote a compiler, Brainfix, that takes a human-readable programming language (also called Brainfix) and compiles this into BF. This project was then abandoned and rebooted in late 2021 with a complete rewrite of the compiler. While working on this project, the idea to build an actual computer to go along with the compiler arose. The Github project page holds an extensive manual to the Brainfix language and compiler; see \cite{brainfix}. Chapter \ref{section:algorithms} goes into detail about some of the BF algorithms implemented by the compiler.
